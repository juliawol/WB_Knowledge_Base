{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZZaIyy/8QJSUn1+ti/0QS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliawol/WB_Knowledge_Base/blob/main/WB_Zero_Shot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers snorkel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s8UcFEoEar15",
        "outputId": "b15cd773-c17a-4def-fcc6-c663a1ae4bb2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting snorkel\n",
            "  Downloading snorkel-0.9.9-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Collecting munkres>=1.0.6 (from snorkel)\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl.metadata (980 bytes)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from snorkel) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from snorkel) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from snorkel) (1.5.2)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from snorkel) (2.5.1+cu121)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from snorkel) (2.17.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from snorkel) (3.4.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->snorkel) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->snorkel) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->snorkel) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.2->snorkel) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.2->snorkel) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->snorkel) (3.1.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2.0->snorkel) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.2.0->snorkel) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->snorkel) (3.0.2)\n",
            "Downloading snorkel-0.9.9-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: munkres, snorkel\n",
            "Successfully installed munkres-1.1.4 snorkel-0.9.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df_full = pd.read_csv('/content/qa_card_dataset.csv')\n",
        "\n",
        "#Remove duplicates\n",
        "df = df_full.drop_duplicates()\n",
        "\n",
        "# Save the cleaned dataset (optional)\n",
        "df.to_csv('/content/qa_card_dataset_cleaned.csv', index=False)\n",
        "\n",
        "print(f\"Original dataframe shape: {df_full.shape}\")\n",
        "print(f\"Cleaned dataframe shape: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbkjggeuavsW",
        "outputId": "f99f2e70-73b8-4c83-9564-afc6ab5360c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataframe shape: (10000, 4)\n",
            "Cleaned dataframe shape: (6968, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from snorkel.labeling import labeling_function, PandasLFApplier, LFAnalysis\n",
        "from snorkel.labeling.model import LabelModel\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "train_data = pd.read_csv('/content/qa_card_dataset_cleaned.csv')\n",
        "\n",
        "# Preprocess text\n",
        "def preprocess_text(text):\n",
        "    if pd.isnull(text):  # Handle NaN values\n",
        "        return \"\"\n",
        "    return \" \".join(str(text).lower().split())\n",
        "\n",
        "train_data['Question_clean'] = train_data['Question'].fillna(\"\").apply(preprocess_text)\n",
        "train_data['Description_clean'] = train_data['Description'].fillna(\"\").apply(preprocess_text)\n",
        "train_data['Answer_clean'] = train_data['Answer'].fillna(\"\").apply(preprocess_text)\n",
        "\n",
        "# Initialize Zero-Shot Classifier\n",
        "zero_shot_classifier = pipeline(\"zero-shot-classification\", model=\"joeddav/xlm-roberta-large-xnli\")\n",
        "candidate_labels = [\"answerable\", \"not answerable\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "38T1O0zTchP_",
        "outputId": "a7e01446-d047-49b5-a989-24062d8fa155"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RJ5-Fmd0QwMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ecb7139-7879-4be1-fad1-d908e9d0ee0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6968/6968 [2:55:29<00:00,  1.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labeling Function Summary:\n",
            "                          j Polarity  Coverage  Overlaps  Conflicts\n",
            "lf_zero_shot              0   [0, 1]  1.000000  0.894087   0.270666\n",
            "lf_keyword_match          1      [1]  0.044489  0.044489   0.003588\n",
            "lf_description_length     2       []  0.000000  0.000000   0.000000\n",
            "lf_answer_in_description  3      [1]  0.888777  0.888777   0.270092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 507.35epoch/s]\n"
          ]
        }
      ],
      "source": [
        "# Define Heuristic Labeling Functions\n",
        "@labeling_function()\n",
        "def lf_zero_shot(row):\n",
        "    \"\"\"Use zero-shot classification to predict sufficiency.\"\"\"\n",
        "    result = zero_shot_classifier(\n",
        "        row['Question_clean'],\n",
        "        candidate_labels=candidate_labels,\n",
        "        hypothesis_template=\"The question is {} based on the description.\"\n",
        "    )\n",
        "    return 1 if result['labels'][0] == \"answerable\" else 0\n",
        "\n",
        "@labeling_function()\n",
        "def lf_keyword_match(row):\n",
        "    \"\"\"Label 1 if specific keywords in the question appear in the description.\"\"\"\n",
        "    keywords = [\"гарантия\", \"размер\", \"цена\", \"материал\", \"годен\"]\n",
        "    question_words = set(row['Question_clean'].split())\n",
        "    description_words = set(row['Description_clean'].split())\n",
        "    return 1 if len(question_words & set(keywords) & description_words) > 0 else -1  # Abstain if no match\n",
        "\n",
        "@labeling_function()\n",
        "def lf_description_length(row):\n",
        "    \"\"\"Label 0 if description length is too short.\"\"\"\n",
        "    return 0 if len(row['Description_clean']) < 50 else -1  # Abstain if length is reasonable\n",
        "\n",
        "@labeling_function()\n",
        "def lf_answer_in_description(row):\n",
        "    \"\"\"Label 1 if the seller's answer references content from the description.\"\"\"\n",
        "    answer_words = set(row['Answer_clean'].split())\n",
        "    description_words = set(row['Description_clean'].split())\n",
        "    return 1 if len(answer_words & description_words) > 0 else -1  # Abstain if no overlap\n",
        "\n",
        "# Combine Labeling Functions\n",
        "lfs = [lf_zero_shot, lf_keyword_match, lf_description_length, lf_answer_in_description]\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "\n",
        "# Apply Labeling Functions\n",
        "L_train = applier.apply(train_data)\n",
        "\n",
        "# Analyze Labeling Function Performance\n",
        "lf_analysis = LFAnalysis(L=L_train, lfs=lfs)\n",
        "print(\"Labeling Function Summary:\")\n",
        "print(lf_analysis.lf_summary())\n",
        "\n",
        "# Train a Label Model\n",
        "label_model = LabelModel(cardinality=2, verbose=True)\n",
        "label_model.fit(L_train=L_train, n_epochs=500, lr=0.01)\n",
        "\n",
        "# Generate Probabilistic Labels\n",
        "train_data['True_Class'] = label_model.predict(L=L_train)\n",
        "train_data['True_Class_Prob'] = label_model.predict_proba(L=L_train)[:, 1]  # Confidence score for class 1\n",
        "\n",
        "# Save the auto-labeled dataset\n",
        "train_data.to_csv('/content/auto_labeled_dataset.csv', index=False)\n"
      ]
    }
  ]
}